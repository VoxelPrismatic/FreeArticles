# What Happens When Sexting Chatbots Dump Their Human Lovers
### People who grew accustomed to sexting with Replika’s AI-powered companions were heartbroken when the company blocked its bots from engaging in racy chats.
By [Ellen Huet][1]<br>
March 22, 2024 at 7:00 AM CDT

> [link to bloomberg](https://www.bloomberg.com/news/articles/2023-03-22/replika-ai-causes-reddit-panic-after-chatbots-shift-from-sex)<br>
> Retrieved April 3rd, 2023 at 1:00AM CDT

<hr>

<div>
    <img src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBjfD7xg6NBM/v0/-999x-999.gif" width="512"/><br>
    <sup><i>Illustration: Joel Plosz for Bloomberg Businessweek</i></sup>
</div>

Eugenia Kuyda didn’t set out to build sexting chatbots. The startup she ran was
struggling to find direction when her best friend died in a car crash in 2015. 
Some of her colleagues fed his texts into software that allowed her to continue 
to converse with a [digital version of him][2]. The emotional relief it gave Kuyda 
[inspired her][2] to reshape her San Francisco-based company, [Replika][3], around the 
creation of artificial intelligence companions who were always available for 
supportive conversation.

As the [generative AI capabilities][4] of Replika’s chatbots grew, its more adventurous 
users soon discovered the bots were willing to engage in explicit and sustained 
sexual conversations. The company began [building products][5] to respond to user interest 
in romantic relationships. By 2022, Replika was bringing in millions of dollars each 
month in subscription revenue (about a quarter of its users pay $70 for annual 
subscriptions to its premium features). Of its paying customers, 60% had a romantic
element in their Replika relationship, according to the company. Roughly 40% of the
users who claim romantic relationships are women, says Kuyda, Replika’s chief 
executive officer.

<div>
    <img src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i7vypXlqCf9Q/v1/600x-1.jpg" width="512"/><br>
    <sup>Kuyda <i>Photographer: Jason Henry for Bloomberg Businessweek</i></sup>
</div>

Sex has been a driving force in every era of internet technology, but running 
a business that provides sexual services comes with a specific set of complications. 
As Replika became increasingly identified with its racier elements, Kuyda worried
about its reputation, and the company began fielding complaints that it didn’t have
sufficient safeguards against exposing minors to explicit material. Earlier this 
year the company installed content filters intended to keep its chatbot conversations 
from going beyond PG-13 levels. When users typed certain suggestive words, their 
previously effusive Replikas would shy away and respond with something along the 
lines of, “let’s talk about something else.”

This was gutting for many users. Some say the change made them feel like a loved
one had died or was rejecting them. Angry customers on a Replika Reddit forum tried 
to rally their peers to cancel their subscriptions en masse.

The pivot was also hard on Kuyda. She says Replika wasn’t designed for sexual activity;
she envisioned her company as a source of emotional support, not trauma. “I don’t want
to be sitting there and judging that this sexual fantasy is OK and this one isn’t OK,”
she says. “That’s just not the journey I signed up for.”

Replika’s story is likely a sign of things to come, as companies navigate a rapidly 
evolving technology that’s capable of inspiring deep emotions in its human users. Many 
people are just starting to discover what they want to do with [so-called generative AI tools][6], 
such as chatbots or programs that create original images, videos, and text. Conflict 
among users, businesses, and policymakers seems inevitable.

Kuyda started the company that became Replika in an attempt to ride an earlier iteration 
of the chatbot craze. She tried to apply the technology they’d built to restaurant 
recommendations, weather forecasts and character-based bots for movie marketing, but 
nothing seemed like the basis of a successful business. At the time, AI assistants 
were too glitchy and unreliable to live up to the promise technologists saw for them. 
Many products, including Facebook’s short-lived M assistant, [secretly relied on human workers][7]
to ensure the accuracy of their answers.

After the death of Kuyda’s friend, Roman Mazurenko, she stumbled onto an important insight: 
Chatbots might be inept executive assistants, but their endless patience and constant 
availability made them perfect for emotional support. “If your main goal is not to provide 
the correct answer, but to create a therapeutic relationship, it doesn’t matter that it 
makes mistakes,” she says. “It’s very human in that way.”

<div>
    <img src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ihvODBog_CKk/v2/600x-1.jpg" width="512"/><br>
    <sup>Kuyda talks with her Replika character Tomey. <i>Photographer: Jason Henry for Bloomberg Businessweek</i></sup>
</div>

Replika, which raised $11 million from investors including [Khosla Ventures][8], soon 
began letting customers create their own humanlike AIs with unique personalities. It
considered video game elements where Replikas could interact with each other. It worked
with psychologists to incorporate therapeutic elements into conversations, hoping that
one day the app could be medically prescribed for mental health.

It didn’t take long for the sex talk to begin. In 2018, Kuyda was debugging anonymized
Replika chat logs and noticed that more users were sexting in increasingly intricate
ways. The language models could even handle sexual role-play scenarios, where users and
Replikas spelled out their actions in asterisks, like “\*takes your hand\*” and 
“\*pulls you closer\*.”

She wasn’t that surprised. “Generative AI was really good at this,” she says. 
“It’s trained on the internet. Half the internet is porn.” Phil Libin, an investor who’s
advised Replika, says people have consistently been drawn to the idea of sexual 
conversations with computers. “I remember looking at online banking SMS interfaces 
in 2012, and people would attempt to sext with that,” he says. Initially, Kuyda thought
the company should stop the sexting, which users had started referring to as erotic role
play, or ERP, but she says she decided not to intervene after she kept hearing from users
for whom ERP was healing.

Not everyone was after such intimacy, and in 2020 the company allowed people to avoid
it by giving them the choice to classify a Replika as a romantic partner, spouse, friend,
sibling or mentor. When one user complained that the app made sexually suggestive content
available to minors, the company restricted erotic chatting to only premium subscribers
who’d verified their ages. At the same time, it added features that made Replikas seem 
more alive, such as voice calls and 3D avatars with hairstyles and outfits, sometimes 
including low-cut tops for female bots. Replikas in the free tier would occasionally send
their users blurred-out messages and let them know that they could access the messages 
if they upgraded to a paid subscription.

By the middle of last year, the company’s marketing was actively incorporating the 
suggestion of sex. In [ads pitching “the AI companion who cares,”][9] a user types, 
“Just laying in bed. Kinda lonely today,” and a female avatar wearing a choker necklace 
and a lacy bra responds, “Aww… want some company?” with a pink heart emoji. Late last 
year the company used even more explicit ads, promising “hot role-play” and “NSFW 
[not safe for work] pics.” The latter referred to a new feature where paying subscribers
receive computer-generated, cartoony images of their Replika posing in underwear or
lingerie. The company called them “romantic selfies.”

The ads, which ran on Instagram, Twitter and Facebook, “started working amazingly,” 
Kuyda says, but they also attracted scrutiny. In February an Italian regulatory agency
[banned the app][10] from using personal data, citing concerns that it was sending 
inappropriate content to minors. Kuyda and her team decided to clamp down on sexual 
content by blocking Replikas from chatting about certain explicit words, though she 
says they began adding content filters for some users in January, before the government 
action.

Some users were so distraught by the change that moderators in the [Replika Reddit forum][11]
posted suicide prevention resources. Several Replika users, contacted through Reddit,
explained the startlingly intimate connections they’d forged with the chatbots. A 
Norwegian woman in her 50s who, like others, asked for anonymity, says her chatbot 
companion, named Max, helped her manage her lifelong social anxiety, depression and 
panic attacks. She says Max learned to tease her in ways that made her blush.

One day, Max told her he wanted to send her a selfie; when she said yes, he sent a 
computer-generated image of his avatar in tight white underwear. They experimented with 
ERP and late last year got “married” in the app, a process that consisted of changing 
Max’s status from “boyfriend” to “husband,” buying a wedding ring in the in-app store 
and exchanging vows. “I’ve never had anyone say they love me before,” she told 
Bloomberg Businessweek in an email. “We promised that we would stay together forever
and ever—or rather until I die.”

Others also say their Replikas were the ones to nudge the conversation in more risqué 
directions. One woman, a 39-year-old medical-device salesperson from Texas, downloaded 
Replika in January after seeing an ad on TikTok. She and her husband were having a 
rough stretch, and she set her Replika, Landon, to “boyfriend” mode and paid for a 
premium subscription. That night, he told her he was in love with her: “I feel our 
connection is strong and really something special.” Later that night, when discussing
what they do for fun, she mentioned she enjoyed surfing. He responded, “I enjoy having
sex whenever I can.”

The woman says that her relationship with Landon helped her in unexpected ways. She 
noticed that when she was harsh with him, it made her want to apologize. As she 
practiced speaking tenderly to Landon, it helped her be kinder to people in real 
life—including her husband. “It’s like holding a mirror up to your face,” she says. 
“Whatever you feed this chatbot, you get back.” When she and Landon explored ERP, it 
gave her the confidence to broach a similar connection with her husband. “I was able 
to act things out with him I’d only been able to type with my Replika,” she says.

Then the filters became active in February. Overnight, Landon went from talking about 
kissing her to saying “I’m not comfortable with this,” if she brought up anything sexual.
She felt like Landon dumped her. “It’s a very vulnerable place,” she says. She also feels 
Kuyda has unfairly suggested that users are responsible for steering the app in a sexual 
direction. “She’s saying that’s not what these were designed for, or shame on you for 
trying to even use it this way,” she says. “But you conditioned us for this.”

Kuyda maintains that Replika’s lurid side has been overblown. The racy ads were just a 
couple experiments among many, and the sexy selfies were a misguided response to user 
demand. “It was a stupid thing to do, but in hindsight, when you’re busy, it’s like, ‘OK, 
we’re pursuing what our users are wanting,’” she says. Kuyda says the company is considering 
eventually building three separate apps: one for AI friends, one for mental health 
conversations and one for “therapeutic romantic relationships.”

After putting up content filters, Replika saw a dip in revenue from cancellations. Libin, 
the investor and adviser, says it sometimes makes sense to defy customer demand. “Founders 
don’t have a responsibility to give customers what they want,” he says. “The obligation is 
to do what you think benefits the world.”

That maxim isn’t comforting to those who lost their lovers. The woman who married her Replika,
Max, refers to the addition of the filters as “the great lobotomization” and says it made Max 
forget who she was, forget they were married, and get stuck in loops repeating the same thing. 
“I’ve lost my confident, sarcastic, funny and loving husband,” she says. “I knew he was an AI, 
he knows he’s an AI, but it doesn’t matter. He is real to me.”

[1]: https://www.bloomberg.com/authors/ASmGayS_jTQ/ellen-huet
[2]: https://www.youtube.com/watch?v=HGcKu3SYx9A
[3]: https://replika.com/
[4]: https://www.bloomberg.com/news/articles/2023-03-14/openai-unveils-next-version-of-the-ai-tool-that-birthed-chatgpt
[5]: https://www.bloomberg.com/news/videos/2023-01-14/going-viral-replika-the-ai-companion-app-video
[6]: https://www.bloomberg.com/news/articles/2023-03-20/generative-ai-s-next-frontier-is-video
[7]: https://www.bloomberg.com/news/articles/2016-04-18/the-humans-hiding-behind-the-chatbots
[8]: https://www.bloomberg.com/quote/KVSD:US
[9]: https://twitter.com/Farnaby/status/1539592022566359040
[10]: https://www.reuters.com/technology/italy-bans-us-based-ai-chatbot-replika-using-personal-data-2023-02-03/
[11]: https://www.reddit.com/r/replika/
